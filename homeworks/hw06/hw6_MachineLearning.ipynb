{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data-X Fall 2018: Homework 06 \n",
    "\n",
    "### Machine Learning\n",
    "\n",
    "**Authors:** Sana Iqbal (Part 1, 2, 3)\n",
    "\n",
    "\n",
    "In this homework, you will do some exercises with prediction.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import otter "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    " # machine learning libraries\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "#import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "grader = otter.Notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Part 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "#### 1.a Read __`diabetesdata.csv`__ file into a pandas dataframe. \n",
    "About the data: __\n",
    "\n",
    "1. __TimesPregnant__: Number of times pregnant \n",
    "2. __glucoseLevel__: Plasma glucose concentration a 2 hours in an oral glucose tolerance test \n",
    "3. __BP__: Diastolic blood pressure (mm Hg)  \n",
    "5. __insulin__: 2-Hour serum insulin (mu U/ml) \n",
    "6. __BMI__: Body mass index (weight in kg/(height in m)^2) \n",
    "7. __pedigree__: Diabetes pedigree function \n",
    "8. __Age__: Age (years) \n",
    "9. __IsDiabetic__: 0 if not diabetic or 1 if diabetic) \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "TimesPregnant  glucoseLevel  BP  insulin   BMI  Pedigree   Age  \\\n0                6         148.0  72        0  33.6     0.627  50.0   \n1                1           NaN  66        0  26.6     0.351  31.0   \n2                8         183.0  64        0  23.3     0.672   NaN   \n3                1           NaN  66       94  28.1     0.167  21.0   \n4                0         137.0  40      168  43.1     2.288  33.0   \n..             ...           ...  ..      ...   ...       ...   ...   \n763             10         101.0  76      180  32.9     0.171  63.0   \n764              2         122.0  70        0  36.8     0.340  27.0   \n765              5         121.0  72      112  26.2     0.245  30.0   \n766              1         126.0  60        0  30.1     0.349  47.0   \n767              1          93.0  70        0  30.4     0.315  23.0   \n\n     IsDiabetic  \n0             1  \n1             0  \n2             1  \n3             0  \n4             1  \n..          ...  \n763           0  \n764           0  \n765           0  \n766           1  \n767           0  \n\n[768 rows x 8 columns]\n"
    }
   ],
   "source": [
    "#Read data & print it\n",
    "data = pd.read_csv('diabetesdata.csv')\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.b Calculate the percentage of NaN values in each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "TimesPregnant    0.000000\nglucoseLevel     0.044271\nBP               0.000000\ninsulin          0.000000\nBMI              0.000000\nPedigree         0.000000\nAge              0.042969\nIsDiabetic       0.000000\ndtype: float64"
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NullsPerColumn = data.isnull().sum(axis=0)/len(data)\n",
    "NullsPerColumn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.c Calculate the TOTAL percent of ROWS with NaN values in the dataframe (make sure values are floats).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "0.08333333333333333"
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PercentNull =  sum(data.isnull().any(axis=1))/len(data)\n",
    "PercentNull"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.d Split __`data`__  into  __`train_df`__ and __`test_df`__  with 15% test split.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split values\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_df, test_df = train_test_split(data, test_size=0.15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.e Replace the Nan values in  __`train_df`__ and __`test_df`__  with the mean of EACH feature.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.fillna(train_df.mean())\n",
    "test_df = test_df.fillna(test_df.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.f Split __`train_df`__ & __`test_df`__   into  __`X_train`__, __`Y_train`__  and __`X_test`__, __`Y_test`__. __`Y_train`__  and __`Y_test`__ should only have the column we are trying to predict,  __`IsDiabetic`__.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_df.iloc[:,:7]\n",
    "Y_train = train_df.loc[:,'IsDiabetic']\n",
    "X_test  = test_df.iloc[:,:7]\n",
    "Y_test = test_df.loc[:,'IsDiabetic']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.g Use this dataset to train perceptron, logistic regression and random forest models using 15% test split. Report training and test accuracies.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "logreg training acuracy=  0.7929447852760736\nlogreg test accuracy=  0.6982758620689655\n"
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "from sklearn import linear_model\n",
    "\n",
    "# use newton-cg solver and 'ovr' for multi_class\n",
    "logreg = linear_model.LogisticRegression(solver = 'newton-cg', multi_class='ovr')\n",
    "\n",
    "logreg.fit(X_train, Y_train)\n",
    "\n",
    "logreg_train_acc = logreg.score(X_train, Y_train)\n",
    "logreg_test_acc = logreg.score(X_test, Y_test)\n",
    "print ('logreg training acuracy= ',logreg_train_acc)\n",
    "print('logreg test accuracy= ',logreg_test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "perceptron training acuracy=  0.4785276073619632\nperceptron test accuracy=  0.5431034482758621\n"
    }
   ],
   "source": [
    "# Perceptron\n",
    "perceptron = linear_model.Perceptron()\n",
    "\n",
    "perceptron.fit(X_train, Y_train)\n",
    "\n",
    "perceptron_train_acc = perceptron.score(X_train, Y_train)\n",
    "perceptron_test_acc = perceptron.score(X_test, Y_test)\n",
    "print ('perceptron training acuracy= ',perceptron_train_acc)\n",
    "print('perceptron test accuracy= ',perceptron_test_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "adaboost training acuracy=  0.8266871165644172\nadaboost test accuracy=  0.7068965517241379\n"
    }
   ],
   "source": [
    "# Adaboost\n",
    "from sklearn import ensemble\n",
    "\n",
    "adaboost = ensemble.AdaBoostClassifier()\n",
    "\n",
    "adaboost.fit(X_train, Y_train)\n",
    "\n",
    "adaboost_train_acc = adaboost.score(X_train, Y_train)\n",
    "adaboost_test_acc = adaboost.score(X_test, Y_test)\n",
    "print ('adaboost training acuracy= ',adaboost_train_acc)\n",
    "print('adaboost test accuracy= ',adaboost_test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "random_forest training acuracy=  1.0\nrandom_forest test accuracy=  0.7413793103448276\n"
    }
   ],
   "source": [
    "# Random Forest\n",
    "random_forest = ensemble.RandomForestClassifier()\n",
    "\n",
    "random_forest.fit(X_train, Y_train)\n",
    "\n",
    "random_forest_train_acc = random_forest.score(X_train, Y_train)\n",
    "random_forest_test_acc = random_forest.score(X_test, Y_test)\n",
    "print('random_forest training acuracy= ',random_forest_train_acc)\n",
    "print('random_forest test accuracy= ',random_forest_test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.h Is mean imputation is the best type of imputation to use? Why or why not? What are some other ways to impute the data?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "better = False \n",
    "explanation = \"I think simply using the average value of that feature is not the best way, as it might eliminate the information contained in the record by NaNs. For example, it is possible that given other features, it can be inferred that the missing value should be high. While filling the NaN with the mean value, it might misleading the model to set a medium-level's value for that condition.\\n There are other ways to impute the data:\\n 1. Fill the Null with 0 or the value before it.\\n 2. Generate an average value based on the categories of other attributes. \\n 3. Simply remove the rows with Null value.\"\n",
    "# [string] write why or why not here, and other ways"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "__2.a Add columns __`BMI_band`__ & __`Pedigree_band`__  to  a new dataframe called __`data2`__  by cutting __`BMI`__ & __`Pedigree`__ into 3 intervals. PRINT the first 5 rows of __`data2`__.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>BMI_band</th>\n      <th>Pedigree_band</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>(22.367, 44.733]</td>\n      <td>(0.0757, 0.859]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>(22.367, 44.733]</td>\n      <td>(0.0757, 0.859]</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>(22.367, 44.733]</td>\n      <td>(0.0757, 0.859]</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>(22.367, 44.733]</td>\n      <td>(0.0757, 0.859]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>(22.367, 44.733]</td>\n      <td>(1.639, 2.42]</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "           BMI_band    Pedigree_band\n0  (22.367, 44.733]  (0.0757, 0.859]\n1  (22.367, 44.733]  (0.0757, 0.859]\n2  (22.367, 44.733]  (0.0757, 0.859]\n3  (22.367, 44.733]  (0.0757, 0.859]\n4  (22.367, 44.733]    (1.639, 2.42]"
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2 = data.loc[:, ['BMI', 'Pedigree']]\n",
    "data2.loc[:, 'BMI_band'], BMI_bins = pd.cut(data2.loc[:, 'BMI'], 3, retbins=True)\n",
    "data2.loc[:, 'Pedigree_band'], Pedigree_bins = pd.cut(data2.loc[:, 'Pedigree'], 3, retbins=True)\n",
    "del data2['BMI']\n",
    "del data2['Pedigree']\n",
    "data2.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__2.b Print the category intervals for __`BMI_band`__ & __`Pedigree_band`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "(22.367, 44.733]     681\n(-0.0671, 22.367]     51\n(44.733, 67.1]        36\nName: BMI_band, dtype: int64"
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2['BMI_band'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "(0.0757, 0.859]    685\n(0.859, 1.639]      74\n(1.639, 2.42]        9\nName: Pedigree_band, dtype: int64"
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2['Pedigree_band'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "BMI_Band_Interval: [(22.367, 44.733], (-0.0671, 22.367], (44.733, 67.1]]\nCategories (3, interval[float64]): [(-0.0671, 22.367] < (22.367, 44.733] < (44.733, 67.1]]\nPedigree_Band_Interval: [(0.0757, 0.859], (1.639, 2.42], (0.859, 1.639]]\nCategories (3, interval[float64]): [(0.0757, 0.859] < (0.859, 1.639] < (1.639, 2.42]]\n"
    }
   ],
   "source": [
    "print('BMI_Band_Interval: ' + str(data2['BMI_band'].unique()))\n",
    "print('Pedigree_Band_Interval: ' + str(data2['Pedigree_band'].unique()))\n",
    "\n",
    "\n",
    "# print('BMI_Band_Interval: ' + str(BMI_bins))\n",
    "# print('Pedigree_Band_Interval: ' + str(Pedigree_bins))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__2.c Group __`data`__ by __`Pedigree_band`__ & determine ratio of diabetic in each band.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>TimesPregnant</th>\n      <th>glucoseLevel</th>\n      <th>BP</th>\n      <th>insulin</th>\n      <th>BMI</th>\n      <th>Pedigree</th>\n      <th>Age</th>\n      <th>IsDiabetic</th>\n    </tr>\n    <tr>\n      <th>Pedigree_band</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>(0.0757, 0.859]</th>\n      <td>2651</td>\n      <td>78485.0</td>\n      <td>47099</td>\n      <td>51856</td>\n      <td>21686.8</td>\n      <td>263.708</td>\n      <td>21783.0</td>\n      <td>224</td>\n    </tr>\n    <tr>\n      <th>(0.859, 1.639]</th>\n      <td>291</td>\n      <td>9036.0</td>\n      <td>5364</td>\n      <td>7835</td>\n      <td>2570.7</td>\n      <td>80.717</td>\n      <td>2475.0</td>\n      <td>40</td>\n    </tr>\n    <tr>\n      <th>(1.639, 2.42]</th>\n      <td>11</td>\n      <td>1305.0</td>\n      <td>610</td>\n      <td>1595</td>\n      <td>312.8</td>\n      <td>17.976</td>\n      <td>257.0</td>\n      <td>4</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "                 TimesPregnant  glucoseLevel     BP  insulin      BMI  \\\nPedigree_band                                                           \n(0.0757, 0.859]           2651       78485.0  47099    51856  21686.8   \n(0.859, 1.639]             291        9036.0   5364     7835   2570.7   \n(1.639, 2.42]               11        1305.0    610     1595    312.8   \n\n                 Pedigree      Age  IsDiabetic  \nPedigree_band                                   \n(0.0757, 0.859]   263.708  21783.0         224  \n(0.859, 1.639]     80.717   2475.0          40  \n(1.639, 2.42]      17.976    257.0           4  "
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.groupby(data2['Pedigree_band']).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "Pedigree_band\n(0.0757, 0.859]    0.327007\n(0.859, 1.639]     0.540541\n(1.639, 2.42]      0.444444\nName: IsDiabetic, dtype: float64"
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pedigree_DiabeticRatio = data.groupby(data2['Pedigree_band'])['IsDiabetic'].mean()\n",
    "pedigree_DiabeticRatio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__2.d Group  __`data`__ by __`BMI_band`__ & determine ratio of diabetic in each band.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "BMI_band\n(-0.0671, 22.367]    0.039216\n(22.367, 44.733]     0.358297\n(44.733, 67.1]       0.611111\nName: IsDiabetic, dtype: float64"
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BMI_DiabeticRatio = data.groupby(data2['BMI_band'])['IsDiabetic'].mean()\n",
    "BMI_DiabeticRatio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__2.e Convert these features - 'BP','insulin','BMI' and 'Pedigree'   into categorical values by mapping different bands of values of these features to integers 0,1,2 in a dataframe called `data3`.__  \n",
    " \n",
    "HINT: USE pd.cut with bin=3 to create 3 bins\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>TimesPregnant</th>\n      <th>glucoseLevel</th>\n      <th>BP</th>\n      <th>insulin</th>\n      <th>BMI</th>\n      <th>Pedigree</th>\n      <th>Age</th>\n      <th>IsDiabetic</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>6</td>\n      <td>148.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>50.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>31.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>8</td>\n      <td>183.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>21.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>137.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>2</td>\n      <td>33.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>763</th>\n      <td>10</td>\n      <td>101.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>63.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>764</th>\n      <td>2</td>\n      <td>122.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>27.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>765</th>\n      <td>5</td>\n      <td>121.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>30.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>766</th>\n      <td>1</td>\n      <td>126.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>47.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>767</th>\n      <td>1</td>\n      <td>93.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>23.0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>768 rows Ã— 8 columns</p>\n</div>",
      "text/plain": "     TimesPregnant  glucoseLevel BP insulin BMI Pedigree   Age  IsDiabetic\n0                6         148.0  1       0   1        0  50.0           1\n1                1           NaN  1       0   1        0  31.0           0\n2                8         183.0  1       0   1        0   NaN           1\n3                1           NaN  1       0   1        0  21.0           0\n4                0         137.0  0       0   1        2  33.0           1\n..             ...           ... ..     ...  ..      ...   ...         ...\n763             10         101.0  1       0   1        0  63.0           0\n764              2         122.0  1       0   1        0  27.0           0\n765              5         121.0  1       0   1        0  30.0           0\n766              1         126.0  1       0   1        0  47.0           1\n767              1          93.0  1       0   1        0  23.0           0\n\n[768 rows x 8 columns]"
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data3 = data.copy()\n",
    "data3.loc[:, 'BP'], BP_bins = pd.cut(data3.loc[:, 'BP'], 3, labels=[0, 1, 2], retbins=True)\n",
    "data3.loc[:, 'insulin'], ins_bins = pd.cut(data3.loc[:, 'insulin'], 3, labels=[0, 1, 2], retbins=True)\n",
    "data3.loc[:, 'BMI'], BMI_bins = pd.cut(data3.loc[:, 'BMI'], 3, labels=[0, 1, 2], retbins=True)\n",
    "data3.loc[:, 'Pedigree'], Ped_bins = pd.cut(data3.loc[:, 'Pedigree'], 3, labels=[0, 1, 2], retbins=True)\n",
    "data3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "__2.f Now consider the original dataset again, instead of generalizing the NAN values with the mean of the feature we will try assigning values to NANs based on some hypothesis. For example for age we assume that the relation between BMI and BP of people is a reflection of the age group. We can have 9 types of BMI and BP relations and our aim is to find the median age of each of that group:__\n",
    "\n",
    "Your Age guess matrix will look like this:  \n",
    "\n",
    "| BMI | 0       | 1      | 2  |\n",
    "|-----|-------------|------------- |----- |\n",
    "| BP  |             |              |      |\n",
    "| 0   | a00         | a01          | a02  |\n",
    "| 1   | a10         | a11          | a12  |\n",
    "| 2   | a20         | a21          |  a22 |\n",
    "\n",
    "\n",
    "__Create a guess_matrix  for NaN values of *'Age'* ( using 'BMI' and 'BP')  and  *'glucoseLevel'*  (using 'BP' and 'Pedigree') for the given dataset and assign values accordingly to the NaNs in 'Age' or *'glucoseLevel'* .__\n",
    "\n",
    "\n",
    "Refer to how we guessed age in the titanic notebook in the class.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "guess_matrix_age = pd.crosstab(data3['BMI'], data3['BP'], values=data3['Age'], aggfunc='mean')\n",
    "guess_matrix_glucoseLevel = pd.crosstab(data3['BP'], data3['Pedigree'], values=data3['glucoseLevel'], aggfunc='mean')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "__2.g Now, convert 'glucoseLevel' and 'Age' features also to categorical variables of 4 categories each in a dataframe called `data4`. PRINT the head of `data4`__\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "data4 = ...\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__2.h Use this dataset (with all features in categorical form) to train perceptron, logistic regression and random forest models using 15% test split. Report training and test accuracies.__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df, test_df = ...\n",
    "X_train = ...\n",
    "Y_train = ...\n",
    "X_test  = ...\n",
    "Y_test= ...\n",
    "X_train.shape, Y_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Logistic Regression\n",
    "logreg = ...\n",
    "logreg.fit(...)\n",
    "logreg_train_acc = ...\n",
    "logreg_test_acc = ...\n",
    "print ('logreg training acuracy= ',logreg_train_acc)\n",
    "print('logreg test accuracy= ',logreg_test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Perceptron\n",
    "perceptron = ...\n",
    "perceptron.fit(...)\n",
    "perceptron_train_acc = ...\n",
    "perceptron_test_acc = ...\n",
    "print ('perceptron training acuracy= ',perceptron_train_acc)\n",
    "print('perceptron test accuracy= ',perceptron_test_acc)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Random Forest\n",
    "random_forest = ...\n",
    "random_forest.fit(...)\n",
    "random_forest_train_acc = ...\n",
    "random_forest_test_acc = ...\n",
    "print ('random_forest training acuracy= ',random_forest_train_acc)\n",
    "print('random_forest test accuracy= ',random_forest_test_acc)"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "data-x"
  },
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('DataX': conda)",
   "language": "python",
   "name": "python37664bitdataxcondadc7c2b614581426fafc69d312a3bbbce"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "nteract": {
   "version": "0.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}