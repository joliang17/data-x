{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data-X Fall 2018: Homework 06 \n",
    "\n",
    "### Machine Learning\n",
    "\n",
    "**Authors:** Sana Iqbal (Part 1, 2, 3)\n",
    "\n",
    "\n",
    "In this homework, you will do some exercises with prediction. Please note that not all tests are visible. There will be further tests on gradescope. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import otter "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    " # machine learning libraries\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "#import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "grader = otter.Notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Part 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "#### 1.a Read __`diabetesdata.csv`__ file into a pandas dataframe. \n",
    "About the data: __\n",
    "\n",
    "1. __TimesPregnant__: Number of times pregnant \n",
    "2. __glucoseLevel__: Plasma glucose concentration a 2 hours in an oral glucose tolerance test \n",
    "3. __BP__: Diastolic blood pressure (mm Hg)  \n",
    "5. __insulin__: 2-Hour serum insulin (mu U/ml) \n",
    "6. __BMI__: Body mass index (weight in kg/(height in m)^2) \n",
    "7. __pedigree__: Diabetes pedigree function \n",
    "8. __Age__: Age (years) \n",
    "9. __IsDiabetic__: 0 if not diabetic or 1 if diabetic) \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read data & print it\n",
    "data = pd.read_csv('diabetesdata.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "\n    \n    \n        <p>All tests passed!</p>\n    \n    ",
      "text/plain": "\n    All tests passed!\n    "
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check('q1a')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.b Calculate the percentage of NaN values in each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "NullsPerColumn = pd.DataFrame(data.isnull().sum(axis=0))/len(data)\n",
    "NullsPerColumn.columns = ['Percentage Null']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "\n    \n    \n        <p>All tests passed!</p>\n    \n    ",
      "text/plain": "\n    All tests passed!\n    "
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check('q1b')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.c Calculate the TOTAL percent of ROWS with NaN values in the dataframe (make sure values are floats).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "PercentNull =  sum(data.isnull().any(axis=1))/len(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.d Split __`data`__  into  __`train_df`__ and __`test_df`__  with 15% test split.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split values\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_df, test_df = train_test_split(data, test_size=0.15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.e Replace the Nan values in  __`train_df`__ and __`test_df`__  with the mean of EACH feature.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.fillna(train_df.mean())\n",
    "test_df = test_df.fillna(test_df.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "\n    \n    \n        <p>All tests passed!</p>\n    \n    ",
      "text/plain": "\n    All tests passed!\n    "
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check('q1e')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.f Split __`train_df`__ & __`test_df`__   into  __`X_train`__, __`Y_train`__  and __`X_test`__, __`Y_test`__. __`Y_train`__  and __`Y_test`__ should only have the column we are trying to predict,  __`IsDiabetic`__.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_df.iloc[:,:7]\n",
    "Y_train = train_df.loc[:,'IsDiabetic']\n",
    "X_test  = test_df.iloc[:,:7]\n",
    "Y_test = test_df.loc[:,'IsDiabetic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "\n    \n    \n        <p>All tests passed!</p>\n    \n    ",
      "text/plain": "\n    All tests passed!\n    "
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check('q1f')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.g Use this dataset to train perceptron, logistic regression and random forest models using 15% test split. Report training and test accuracies.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "logreg training acuracy=  0.7898773006134969\nlogreg test accuracy=  0.7241379310344828\n"
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "from sklearn import linear_model\n",
    "\n",
    "# use newton-cg solver and 'ovr' for multi_class\n",
    "logreg = linear_model.LogisticRegression(solver = 'newton-cg', multi_class='ovr')\n",
    "\n",
    "logreg.fit(X_train, Y_train)\n",
    "\n",
    "logreg_train_acc = logreg.score(X_train, Y_train)\n",
    "logreg_test_acc = logreg.score(X_test, Y_test)\n",
    "print ('logreg training acuracy= ',logreg_train_acc)\n",
    "print('logreg test accuracy= ',logreg_test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "perceptron training acuracy=  0.6794478527607362\nperceptron test accuracy=  0.5862068965517241\n"
    }
   ],
   "source": [
    "# Perceptron\n",
    "perceptron = linear_model.Perceptron()\n",
    "\n",
    "perceptron.fit(X_train, Y_train)\n",
    "\n",
    "perceptron_train_acc = perceptron.score(X_train, Y_train)\n",
    "perceptron_test_acc = perceptron.score(X_test, Y_test)\n",
    "print ('perceptron training acuracy= ',perceptron_train_acc)\n",
    "print('perceptron test accuracy= ',perceptron_test_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "adaboost training acuracy=  0.8328220858895705\nadaboost test accuracy=  0.7672413793103449\n"
    }
   ],
   "source": [
    "# Adaboost\n",
    "from sklearn import ensemble\n",
    "\n",
    "adaboost = ensemble.AdaBoostClassifier()\n",
    "\n",
    "adaboost.fit(X_train, Y_train)\n",
    "\n",
    "adaboost_train_acc = adaboost.score(X_train, Y_train)\n",
    "adaboost_test_acc = adaboost.score(X_test, Y_test)\n",
    "print ('adaboost training acuracy= ',adaboost_train_acc)\n",
    "print('adaboost test accuracy= ',adaboost_test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "random_forest training acuracy=  1.0\nrandom_forest test accuracy=  0.7327586206896551\n"
    }
   ],
   "source": [
    "# Random Forest\n",
    "random_forest = ensemble.RandomForestClassifier()\n",
    "\n",
    "random_forest.fit(X_train, Y_train)\n",
    "\n",
    "random_forest_train_acc = random_forest.score(X_train, Y_train)\n",
    "random_forest_test_acc = random_forest.score(X_test, Y_test)\n",
    "print('random_forest training acuracy= ',random_forest_train_acc)\n",
    "print('random_forest test accuracy= ',random_forest_test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.h Is mean imputation is the best type of imputation to use? Why or why not? What are some other ways to impute the data?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "better = False \n",
    "explanation = \"I think simply using the average value of that feature is not the best way, as it might eliminate the information contained in the record by NaNs. For example, it is possible that given other features, it can be inferred that the missing value should be high. While filling the NaN with the mean value, it might misleading the model to set a medium-level's value for that condition.\\n There are other ways to impute the data:\\n 1. Fill the Null with 0 or the value before it.\\n 2. Generate an average value based on the categories of other attributes. \\n 3. Simply remove the rows with Null value.\"\n",
    "# [string] write why or why not here, and other ways"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "__2.a Add columns __`BMI_band`__ & __`Pedigree_band`__  to  a new dataframe called __`data2`__  by cutting __`BMI`__ & __`Pedigree`__ into 3 intervals. PRINT the first 5 rows of __`data2`__.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>BMI_band</th>\n      <th>Pedigree_band</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>(22.367, 44.733]</td>\n      <td>(0.0757, 0.859]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>(22.367, 44.733]</td>\n      <td>(0.0757, 0.859]</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>(22.367, 44.733]</td>\n      <td>(0.0757, 0.859]</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>(22.367, 44.733]</td>\n      <td>(0.0757, 0.859]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>(22.367, 44.733]</td>\n      <td>(1.639, 2.42]</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "           BMI_band    Pedigree_band\n0  (22.367, 44.733]  (0.0757, 0.859]\n1  (22.367, 44.733]  (0.0757, 0.859]\n2  (22.367, 44.733]  (0.0757, 0.859]\n3  (22.367, 44.733]  (0.0757, 0.859]\n4  (22.367, 44.733]    (1.639, 2.42]"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2 = data.loc[:, ['BMI', 'Pedigree']]\n",
    "data2.loc[:, 'BMI_band'], BMI_bins = pd.cut(data2.loc[:, 'BMI'], 3, retbins=True)\n",
    "data2.loc[:, 'Pedigree_band'], Pedigree_bins = pd.cut(data2.loc[:, 'Pedigree'], 3, retbins=True)\n",
    "del data2['BMI']\n",
    "del data2['Pedigree']\n",
    "data2.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__2.b Print the category intervals for __`BMI_band`__ & __`Pedigree_band`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "BMI_Band_Interval: [(22.367, 44.733], (-0.0671, 22.367], (44.733, 67.1]]\nCategories (3, interval[float64]): [(-0.0671, 22.367] < (22.367, 44.733] < (44.733, 67.1]]\nPedigree_Band_Interval: [(0.0757, 0.859], (1.639, 2.42], (0.859, 1.639]]\nCategories (3, interval[float64]): [(0.0757, 0.859] < (0.859, 1.639] < (1.639, 2.42]]\n"
    }
   ],
   "source": [
    "print('BMI_Band_Interval: ' + str(data2['BMI_band'].unique()))\n",
    "print('Pedigree_Band_Interval: ' + str(data2['Pedigree_band'].unique()))\n",
    "\n",
    "\n",
    "# print('BMI_Band_Interval: ' + str(BMI_bins))\n",
    "# print('Pedigree_Band_Interval: ' + str(Pedigree_bins))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__2.c Group __`data`__ by __`Pedigree_band`__ & determine ratio of diabetic in each band.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Pedigree_band</th>\n      <th>IsDiabetic</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>(0.0757, 0.859]</td>\n      <td>0.327007</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>(0.859, 1.639]</td>\n      <td>0.540541</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>(1.639, 2.42]</td>\n      <td>0.444444</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "     Pedigree_band  IsDiabetic\n0  (0.0757, 0.859]    0.327007\n1   (0.859, 1.639]    0.540541\n2    (1.639, 2.42]    0.444444"
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pedigree_DiabeticRatio = pd.DataFrame()\n",
    "pedigree_DiabeticRatio['IsDiabetic'] = data.groupby(data2['Pedigree_band'])['IsDiabetic'].mean()\n",
    "pedigree_DiabeticRatio.reset_index(level=0, inplace=True)\n",
    "pedigree_DiabeticRatio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__2.d Group  __`data`__ by __`BMI_band`__ & determine ratio of diabetic in each band.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>BMI_band</th>\n      <th>IsDiabetic</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>(-0.0671, 22.367]</td>\n      <td>0.039216</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>(22.367, 44.733]</td>\n      <td>0.358297</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>(44.733, 67.1]</td>\n      <td>0.611111</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "            BMI_band  IsDiabetic\n0  (-0.0671, 22.367]    0.039216\n1   (22.367, 44.733]    0.358297\n2     (44.733, 67.1]    0.611111"
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# BMI_DiabeticRatio = data.groupby(data2['BMI_band'])['IsDiabetic'].mean()\n",
    "# BMI_DiabeticRatio\n",
    "BMI_DiabeticRatio = pd.DataFrame()\n",
    "BMI_DiabeticRatio['IsDiabetic'] = data.groupby(data2['BMI_band'])['IsDiabetic'].mean()\n",
    "# BMI_DiabeticRatio['BMI_band'] = BMI_DiabeticRatio.index\n",
    "BMI_DiabeticRatio.reset_index(level=0, inplace=True)\n",
    "BMI_DiabeticRatio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__2.e Convert these features - 'BP','insulin','BMI' and 'Pedigree'   into categorical values by mapping different bands of values of these features to integers 0,1,2 in a dataframe called `data3`.__  \n",
    " \n",
    "HINT: USE pd.cut with bin=3 to create 3 bins\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "data3 = data.copy()\n",
    "data3.loc[:, 'BP'], BP_bins = pd.cut(data3.loc[:, 'BP'], 3, labels=[0, 1, 2], retbins=True)\n",
    "data3.loc[:, 'insulin'], ins_bins = pd.cut(data3.loc[:, 'insulin'], 3, labels=[0, 1, 2], retbins=True)\n",
    "data3.loc[:, 'BMI'], BMI_bins = pd.cut(data3.loc[:, 'BMI'], 3, labels=[0, 1, 2], retbins=True)\n",
    "data3.loc[:, 'Pedigree'], Ped_bins = pd.cut(data3.loc[:, 'Pedigree'], 3, labels=[0, 1, 2], retbins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "__2.f Now consider the original dataset again, instead of generalizing the NAN values with the mean of the feature we will try assigning values to NANs based on some hypothesis. For example for age we assume that the relation between BMI and BP of people is a reflection of the age group. We can have 9 types of BMI and BP relations and our aim is to find the median age of each of that group:__\n",
    "\n",
    "Your Age guess matrix will look like this:  \n",
    "\n",
    "| BMI | 0       | 1      | 2  |\n",
    "|-----|-------------|------------- |----- |\n",
    "| BP  |             |              |      |\n",
    "| 0   | a00         | a01          | a02  |\n",
    "| 1   | a10         | a11          | a12  |\n",
    "| 2   | a20         | a21          |  a22 |\n",
    "\n",
    "\n",
    "__Create a guess_matrix  for NaN values of *'Age'* ( using 'BMI' and 'BP')  and  *'glucoseLevel'*  (using 'BP' and 'Pedigree') for the given dataset and assign values accordingly to the NaNs in 'Age' or *'glucoseLevel'* .__\n",
    "\n",
    "\n",
    "Refer to how we guessed age in the titanic notebook in the class.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "guess_matrix_age = np.array(pd.crosstab(data3['BMI'], data3['BP'], values=data3['Age'], aggfunc='median'))\n",
    "guess_matrix_glucoseLevel = np.array(pd.crosstab(data3['BP'], data3['Pedigree'], values=data3['glucoseLevel'], aggfunc='median'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, 3):\n",
    "    for j in range(0, 3):\n",
    "        data3.loc[(data3['Age'].isnull()) & (data3['BMI'] == i) & (data3['BP'] == j),'Age'] = guess_matrix_age[i,j]\n",
    "        data3.loc[(data3['glucoseLevel'].isnull()) & (data3['BP'] == i) & (data3['Pedigree'] == j),'glucoseLevel'] = guess_matrix_glucoseLevel[i,j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "\n    \n    \n        <p>All tests passed!</p>\n    \n    ",
      "text/plain": "\n    All tests passed!\n    "
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check('q2f')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "__2.g Now, convert 'glucoseLevel' and 'Age' features also to categorical variables of 4 categories each in a dataframe called `data4`. PRINT the head of `data4`__\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "data4 = data3.copy()\n",
    "data4.loc[:, 'glucoseLevel'], glu_bins = pd.cut(data4.loc[:, 'glucoseLevel'], 4, labels=[0, 1, 2, 3], retbins=True)\n",
    "data4.loc[:, 'Age'], Age_bins = pd.cut(data4.loc[:, 'Age'], 4, labels=[0, 1, 2, 3], retbins=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "\n    \n    \n        <p>All tests passed!</p>\n    \n    ",
      "text/plain": "\n    All tests passed!\n    "
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check('q2g')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__2.h Use this dataset (with all features in categorical form) to train perceptron, logistic regression and random forest models using 15% test split. Report training and test accuracies.__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "((652, 7), (652,), (116, 7))"
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df, test_df = train_test_split(data4, test_size=0.15)\n",
    "X_train = train_df.iloc[:,:7]\n",
    "Y_train = train_df.loc[:,'IsDiabetic']\n",
    "X_test  = test_df.iloc[:,:7]\n",
    "Y_test = test_df.loc[:,'IsDiabetic']\n",
    "X_train.shape, Y_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "logreg training acuracy=  0.7438650306748467\nlogreg test accuracy=  0.7586206896551724\n"
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "logreg = linear_model.LogisticRegression(solver = 'newton-cg', multi_class='ovr')\n",
    "\n",
    "logreg.fit(X_train, Y_train)\n",
    "\n",
    "logreg_train_acc = logreg.score(X_train, Y_train)\n",
    "logreg_test_acc = logreg.score(X_test, Y_test)\n",
    "print ('logreg training acuracy= ',logreg_train_acc)\n",
    "print('logreg test accuracy= ',logreg_test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "perceptron training acuracy=  0.7239263803680982\nperceptron test accuracy=  0.7758620689655172\n"
    }
   ],
   "source": [
    "# Perceptron\n",
    "perceptron = linear_model.Perceptron()\n",
    "\n",
    "perceptron.fit(X_train, Y_train)\n",
    "\n",
    "perceptron_train_acc = perceptron.score(X_train, Y_train)\n",
    "perceptron_test_acc = perceptron.score(X_test, Y_test)\n",
    "print ('perceptron training acuracy= ',perceptron_train_acc)\n",
    "print('perceptron test accuracy= ',perceptron_test_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "random_forest training acuracy=  0.8650306748466258\nrandom_forest test accuracy=  0.7327586206896551\n"
    }
   ],
   "source": [
    "# Random Forest\n",
    "random_forest = ensemble.RandomForestClassifier()\n",
    "\n",
    "random_forest.fit(X_train, Y_train)\n",
    "\n",
    "random_forest_train_acc = random_forest.score(X_train, Y_train)\n",
    "random_forest_test_acc = random_forest.score(X_test, Y_test)\n",
    "print('random_forest training acuracy= ',random_forest_train_acc)\n",
    "print('random_forest test accuracy= ',random_forest_test_acc)"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "data-x"
  },
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('DataX': conda)",
   "language": "python",
   "name": "python37664bitdataxcondadc7c2b614581426fafc69d312a3bbbce"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "nteract": {
   "version": "0.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}